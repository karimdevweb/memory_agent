{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62746c28",
   "metadata": {},
   "source": [
    "## start by importing all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782c54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import ollama\n",
    "import os\n",
    "from google import genai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = None \n",
    "while True: \n",
    "    msg = input(\"Vous : \") \n",
    "    if \"je m'appelle\" in msg.lower(): \n",
    "        user_name = msg.split()[-1] \n",
    "        print(f\"Enchanté {user_name} !\") \n",
    "    elif \"mon nom\" in msg.lower() and user_name: \n",
    "        print(f\"Tu t'appelles {user_name}.\") \n",
    "    else: \n",
    "        print(\"Je ne me souviens pas, désolé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be685a68",
   "metadata": {},
   "source": [
    "## create an agent wwith memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cf11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Create model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 2. Prompt with memory placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Tu es un assistant utile.\"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 3. Build chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# 4. Use a single memory for the whole conversation\n",
    "memory = ChatMessageHistory()\n",
    "\n",
    "# 5. Wrap with memory\n",
    "chat = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda _: memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 6. Chat like before\n",
    "print(chat.invoke({\"input\": \"Bonjour, je m'appelle André.\"}).content)\n",
    "print(chat.invoke({\"input\": \"Quel est mon nom ?\"}).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff476c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c28bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc3f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a70a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6557a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
